## 课程目录

------

###  第六天

> easymall

> `easymall`
>
> > parent
> >
> > > 维护管理easymall整个项目的资源版本统一
> > >
> > > 依赖版本,和资源
> > >
> > > 构建的各种插件
> >
> > common
> >
> > > 多个子工程 公用的代码,提取到一个公用工程被所有子工程依赖使用(工具类,模板类)
> > >
> > > 继承parent
>
> javabean规范
>
> > entity
> >
> > > 严格对应一个表格的字段
> >
> > domain
> >
> > > 一个表关联另一张表
> >
> > vo
> >
> > > 后台 ------ > 前端数据 
> >
> > dto
> >
> > > 前端 ---- > 后台数据
> >
> > pojo
> >
> > > 所有满足javabean规范数据的统称
>
> 开发商品系统和功能
>
> > 首页商品全部分页查询
> >
> > 根据id查询单个商品
> >
> > 新增商品
> >
> > 商品的更新







### 第七天

> easymall + redis

> 图片上传系统
>
> > 获取网页地址和需要存储到的磁盘地址
> >
> > > 在配置文件中已经做了
> >
> > 1.判断图片是否合法
> >
> > > 以`.jpg	.png	`等结尾
> > >
> > > > 获取上传文件的源文件名称（`getOriginalFilename`）
> > > >
> > > > 截取文件后缀
> > > >
> > > > 判断是否合法
> >
> > 2.生成一个共用路径
> >
> > 3.根据公用路径，访问静态文件
> >
> > > 直接调用工具类
> > >
> > > > 根据路径生成文件夹
> > > >
> > > > > 判断路径是否存在
> > > > >
> > > > > 生成的文件夹有多级目录
> > > > >
> > > > > > 防止一个文件夹中出现大量文件，导致查询效率低下
> >
> > 4.重命名文件
> >
> > > 使用工具类(`randomUUID`)
> >
> > 5.将pic输出到磁盘已建好的目录中
> >
> > > `pic.transferTo(new File(diskDir + fileName));`
> > >
> > > 需要判断是否成功
> >
> > 6.生成url地址
> >
> > > 网页可以直接访问静态图片的地址
> >
> > 返回数据
>
> 
>
> 用户系统
>
> 
>
> redis
>
> > reids介绍
> >
> > > `NOSQL`，`KEY-VALUE` 内存，可持久化，非关系型数据
> > >
> > > > 缓存雪崩
> >
> > 非关系型数据库
> >
> > > 关系型数据库	`oracle`	`mysql`	`sqlServer`
> > >
> > > > 数据结构上的关系
> > > >
> > > > > 1对1
> > > > >
> > > > > 1对多
> > > > >
> > > > > 多对多
> > >
> > > 非关系型数据库	`mongoDb`	`redis`
> > >
> > > > 无法体现数据的关联
> > > >
> > > > > 常用的	`key-value`
> >
> > redis在云主机上的安装
> >
> > > 解压
> > >
> > > > `tar -xvf redis-3.2.11.tar.gz`
> > >
> > > 编译和编译安装
> > >
> > > > `make && make install`
> >
> > redis的脚本启动和运行
> >
> > > 服务端启动
> > >
> > > > `redis-service [配置文件]`
> > > >
> > > > `redis-service &`	:后台运行
> > > >
> > > > `ps | grep redis`	查看是否运行成功
> >
> > > 客户端登陆
> > >
> > > > `redis-cli -p 端口(默认6379) -h ip地址(默认127.0.0.1)`
> >
> > 
> > redis基础命令







### 第八天

> redis五种数据结构 + jedis

> redis五种数据结构
>
> > `String`:	字符串
> >
> > `Hash`:	面向对象的结构
> >
> > `List`:	双向链表
> >
> > `Set`:	集合
> >
> > `ZSet`:	有序集合
>
> 操作命令
>
> > `keys`
> >
> > > 查看key值	`keys *`
> >
> > `set key value [NX/XX]`
> >
> > > 存储key-value数据
> >
> > `get key`
> >
> > > 获取key对应的value
> >
> > `del key`
> >
> > > 根据key值，删除数据
> >
> > `select 整数`
> >
> > > 选择分区，默认一共有16个分库（0---15）
> >
> > `exists key [key] [key]`
> >
> > > 判断当前节点是都包含key
> >
> > `save`
> >
> > > 将当前内存数据保存到磁盘文件
> >
> > `flushall`
> >
> > > 清空所有分库的数据
> >
> > `flushdb`
> >
> > > 清空当前分库的数据
> >
> > `expire key seconds`
> >
> > > 设置缓存数据存储的时间（/秒）
> >
> > `pexpire key milliseconds`
> >
> > > 设置缓存数据存储时间（/毫秒）
> >
> > `ttl key`
> >
> > > 查看一个key的超时剩余时间（/秒）
> >
> > `pttl key`
> >
> > > 查看一个key的剩余超时时间（/毫秒）
> >
> > `help 命令`
> >
> > > 查看命令使用详情，可以直接上官网看详细版
>
> String的命令(略)
>
> > 数据结构图（略）
> >
> > key-value
>
> Hash的命令（略）
>
> > 数据结构图（略）
> >
> > `hset user name wang`
> >
> > `hset user age 18`
>
> List的命令（略）
>
> > 数据结构图（略）
> >
> > `lpush list01 100 200 300 400`	存储的value可以重复
>
> Set的命令（略）
>
> > 数据结构图（略）
> >
> > `sadd facor math history`	存储的value不能重复
>
> ZSet的命令（略）
>
> > 数据结构图（略）
>
> 
>
> redis的多实例配置启动
>
> > `配置文件redis.config`
> >
> > > 详细见笔记
> >
> > > redis配置数据大小的单位
> > >
> > > 绑定可以访问redis服务的ip地址
> > >
> > > 保护模式的使用
> > >
> > > 开启服务的端口
> > >
> > > 后台守护进程是否开启
> > >
> > > 日志输出地址
> > >
> > > 指定持久化的策略
> > >
> > > 数据淘汰策略
> > >
> > > 容量上限
>
> 启动节点
>
> > `[root@10-9-39-13 redis-3.2.11]# redis-server [配置文件]`
>
> 
>
> jedis
>
> > `new ObjectMapper().writeValueAsString(Object);`	将数据转化为json格式
>
> > 实现功能
> >
> > > 用户登录校验
> > >
> > > 状态的获取







### 第九天

> 数据分片算法 + 整合jedis到springboot + redis集群高可用 + 哨兵集群

> redis的分布式结构
>
> > 数据分片
> >
> > > 数据通过计算分成不同的部分，存储在不同的数据节点
>
> 分布式的算法(Hash取余，Hash一致性)
>
> > `hash取余`
> >
> > > `(key.hashCode()&Integer.MAX_VALUE)%N`
> > >
> > > > 括号中的是正整数，N 是分片的节点个数
> >
> > `hash一致性计算原理(详见老师笔记，有图解)`
> >
> > > 任何计算机中的对象都可以通过散列方法获取一个整数值,整数区间[0,2^32-1]
> > >
> > > 这个整数区间--hash环
> >
> > > Hash一致性算法的节点映射关系
> > >
> > > > ip+port
> > > >
> > > > 字符通过散列计算，在hash环上映射成一个整数值
> > >
> > > 数据分片计算方法
> > >
> > > > key顺时针寻找最近的节点
> > >
> > > 数据平衡性(权重)
> > >
> > > > 虚拟节点
> > > >
> > > > > 160*权重值
> > > >
> > > > > 从虚拟节点和真实节点的关系找打真实节点
> >
> > 如何解决扩容迁移量较大的问题
> >
> > > hash取余（一种成熟的分片算法）
> > >
> > > > 无法迁移数据，容易造成雪崩
> > >
> > > hash一致性
> > >
> > > > 节点越多，需要迁移的数据越少
> > > >
> > > > 但会发生数据倾斜
> > > >
> > > > key值和value强耦合
>
> 
>
>
> 整合jedis到springboot（待优化 ----》 最终版本为rediscluster）
>
> > 使用分片连接池管理redis的分布式集群
>
> > 目的
> >
> > > 连接池以单例的形式存放在容器中
> > >
> > > 以免获取关，闭连接时造成资源的浪费
>
> 
>
> redis集群的高可用
>
> > 单节点分布式集群的问题
> >
> > > 不具备分片的高可用
> >
> > redis的主从搭建
> >
> > > redis支持一主多从
> >
> > > 准备配置文件
> > >
> > > > `[root@10-9-39-13 redis-3.2.11]# cp redis.conf 6382redis.conf`
> > >
> > > 启动节点
> > >
> > > > `[root@10-9-104-184 redis-3.2.11]# redis-server 6382redis.conf`
> > >
> > > 查看节点主从状态
> > >
> > > > `127.0.0.1:6382>info replication `
> > > >
> > > > 默认创建的节点都是主节点
> > >
> > > 设置从节点
> > >
> > > > `127.0.0.1:6384> slaveof 10.9.104.184 6382`
>
>
> 哨兵集群
>
> > 监听管理一个主从结构
>
> > 哨兵集群原理
> >
> > > 监听
> > >
> > > > 通过心跳机制（rpc远程控制协议）判断存活
> > >
> > > 过半投票
> > >
> > > > 主节点宕机，哨兵及群发器投票，票数过半执行后续逻辑
> >
> > 代码
> >
> > > 略







### 第十天

> Hash槽 + redisCluster 搭建

> redis-cluster
>
> > 集群中的服务器两两相连
>
> > 特性
> >
> > > 两两互连
> > >
> > > > 通过集群内部二进制通信协议，优化了传输速率
> > >
> > > 哨兵进程消失
> > >
> > > > 哨兵进程的逻辑还在，监听，投票，至少需要三个主节点
> > >
> > > 客户端
> > >
> > > > 客户端不需要关心数据的分布式计算
> > >
> > > 算法
> > >
> > > > 分布式不再使用hash一致性算法，引入了新的逻辑，hash槽
> >
> > hash槽的使用逻辑
> >
> > > 客户端发送命令到任意一个节点（M1）	（name）
> > >
> > > 节点计算好槽号	（5789）
> > >
> > > 节点判定key值的归属权	（1/0）
> > >
> > > 节点通过槽逻辑找到正确的管理者（M1）
> > >
> > > 客户端重新连接重定向到M2发送命令
> > >
> > > M2执行槽计算，判断归属权（true），处理数据
>
> > redis-cluster的搭建
> >
> > > 略
>
> > redis-cluster集群的重新搭建
> >
> > > 略

> 槽道原理
>
> > 槽道原理解决的两个问题
> >
> > > 槽道的管理权如何判断（16384位的二进制（位序列））
> > >
> > > 管理权不所属，如何从大量的集群节点中获取正确管理者进行转发（16384个元素的数组（索引数组））
>
> 节点启动和握手
>
> > 所有节点启动时，将自己的信息封装到一个对象中，保存在内存
>
> > 创建集群`redis-trib.rb	creat`
> >
> > > 底层调用redis命令，节点之间进行握手
> > >
> > > 握手之后，每个节点都保存了所有集群的对象数据
>
> 槽道结构
>
> > 槽分为两个部分
> >
> > > 16384位的二进制（2048个元素的byte数组）
> > >
> > > > 表示节点初始化的状态，1：true，0：false
> > > >
> > > > 1：表示当前节点管理这个槽道
> > > >
> > > > 0：当前节点部管理这个槽道
> > >
> > > 16384个元素的数组（引用对象）
> > >
> > > > 搭建好集群后，所有的节点维护一个完全相同的内存数组
> > > >
> > > > [0-16383]
> > > >
> > > > > 每一个下标对应了槽道好管理节点对象的信息


