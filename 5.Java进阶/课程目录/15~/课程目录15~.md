## 课程目录

----

### 第十五天

> 索引（luncene） + REST风格 

> 索引（luncene）
>
> > 根据一定规则排序，具有一定数据结构的，能够快速定位数据的一批数据
>
> 索引结构的引用（mysql (B + TREE)）
>
> > 在树中有不同的节点，每一个节点都是技术底层的文件系统管理的文件单元Unit
> >
> > 数据单元可以是4K，也可以是8K，量越大，数据越多，磁头寻址越少
> >
> > 树状，第一个节点（根节点），中间节点（枝节点），最后一个节点（叶节点）
>
> 全文检索，索引文件
>
> > 倒排索引算法
> >
> > > 分词/词项/词条话
> >
> > > 倒排索引的步骤
> > >
> > > > 1.收集数据源封装对象
> > > >
> > > > 2.对所有的数据对象`document`中的内容进行属性的分词计算
> > > >
> > > > 3.计算结果是重复的分词则进行合并
> > > >
> > > > 4.将数据`document`合并输出存储，在磁盘形成索引文件结构
>
> 
>
> luncene
>
> > `luncene`是全文检索引擎包,它的出现极大的提升了搜索的开发效率
>
> > 特点
> >
> > > 基于java，对其它语言不友好
> > >
> > > 索引稳定
> > >
> > > 提供丰富的搜索功能
> > >
> > > > 词项，多域搜索，布尔搜索，范围搜索
>
> > luncene底层使用的是浅查询
> >
> > > 浅查询
> > >
> > > > 多级查询，第一级不获取数据，获取的是数据的标识
> > > >
> > > > 下一级才能获取数据
> > >
> > > 深查询
> > >
> > > > 第一级查询就将需要的数据直接获取到最后的页数和条数对应的内容
> > > >
> > > > 前面的所有数据都读取了，但并不适用
>
> 
>
> luncene的分词实现
>
> > `luncene实现的分词器`
> >
> > > 代码
> > >
> > > > luncene实现分词器
> > > >
> > > > > 略
> > > >
> > > > luncene测试有关的依赖
> > > >
> > > > > 略
> > > >
> > > > 分词器测试代码
> > > >
> > > > > 略
> >
> > > `WhitespaceAnalyzer`:空格分词器 
> > >
> > > `StandardAnalyzer`:标准分词器(一个字符分一个词项)
> > >
> > > `SimpleAnalyzer`:一个标点符号分一个词项(句)
> > >
> > > `SmartChineseAnalyzer`:智能中文分词器
> > >
> > > `IKAnalzyer`:常用的一个中文分词器,支持词语的扩展和停用
>
> IK分词器
>
> > 依赖
> >
> > > 略
> >
> > `IKAnalyzer.cfg.xml`
> >
> > > 略
> >
> > 创建索引代码
> >
> > > 略
>
> 问题
>
> > TextField和StringField区别
> >
> > > TextField需要对域的值进行分词的计算
> > >
> > > StringField不需要对域的值进行分词计算(productId,url)
> >
> > Store YES/NO
> >
> > > YES:表示索引文件中在处理document时需要存储数据
> > >
> > > NO:表示document域数据不存储在索引中
> > >
> > > 影响:查询的结果,对于NO的数据是获取不到的
> >
> > POINT的使用
> >
> > > Point类型只保留一个field的数字特性属性(范围查询)
> > >
> > > 即不计算分词,也不存储 如果需要使用这个field的值
> > >
> > > 可以配合同名域的StringField类型 对一个域做多个属性的添加
>
> 
>
> lucene的搜索功能
>
> > 词项查询
> >
> > > 提供一个封装号的Term对象(域名,词项值),利用底层分词结果比对索引中的分词合并结果,要不找到对应值,要不找不到.所有其他查询功能的基础
> >
> > > 代码
> > >
> > > > 略
>
> > 多域查询
> >
> > > 可以在一个查询条件中,使用多个不同的域名实现搜索的功能.
> > >
> > > 基于termQuery实现的,可以对一个关键字进行解析形成多个词项,对多个与做排列组合的结果,获取最终并集
> >
> > > 代码
> > >
> > > > 略
>
> > 布尔查询
> >
> > > 当系统存在多个查询条件时query,单独运行都能对应到一批结果集.可以利用布尔查询,封装查询条件获取所有query之间的逻辑集合
> >
> > > `MUST`必须包含这个子条件结果
> > >
> > > `MUST_NOT`必须不包含子条件结果\
> > >
> > > `SHOULD`可以包含子条件结果
> > >
> > > `FILTER和MUST` 对应这个子条件的所有结果没有评分
> >
> > > 代码
> > >
> > > > 略
>
> > 范围查询
> >
> > > 在数据中存在非常多的与数字特性有关的内容,价钱,容量,尺寸等
> > >
> > > 域属性中如果需要范围查询对应搜索到document,必须制定**Point类型
> > >
> > > **Point不做分词,也不做索引的存储
> > >
> > > 配合StringField来获取想要的数据内容
> >
> > > 代码
> > >
> > > > 略
>
> > 模糊查询
> >
> > > 例如:数据存储的是trump 特朗普,查询时tramp也可以将数据查询出来,使用模糊查询 精确度匹配不高,日和曰
>
> > 通配符查询
> >
> > > 可以使用?代替一个字符
> > >
> > > `Query query=new WildcartQuery(new Term("productName","三?"));`
> > >
> > > 可以查到所有词项中以三开头的2个字符的数据
>
>
> luncene问题
>
> > 对其他语言不方便，只支持java
> >
> > 不能实现对索引的保护和管理
>
> 
>
> Rest风格（RestFull）
>
> > `elasticsearch`完全基于http协议的rest风格设计的技术,
> >
> > `springmvc`也是支持REST风格的
>
> > Rest风格举例
> >
> > > 不符合风格演示url(对user做操作)
> > >
> > > > `http://localhost:10000/user/manage/update`
> > > >
> > > > `http://localhost:10000/user/manage/save`
> > >
> > > 符合Rest风格的url
> > >
> > > > `http://localhost:10000/user/manage/{userId}`
> >
> > `elasticsearch`遵循REST风格
> >
> > > `put:http://elasticsearch/index01 新增索引`
> > >
> > > `get:http://elasticsearch/index01 查询索引`
> > >
> > > `delete:http://elasticsearch/index01 删除索引`







### 第十六天

> ELASTICSEARCH + ELASTICSEARCH集群的搭建

###### ELASTICSEARCH

> ELASTICSEARCH
>
> > ES的结构
> >
> > > es是基于lucene实现的搜索服务，可以通过HTTP服务，最寻RESTFULL风格的访问。
> >
> > es封装的luncene的结构
> >
> > > 笔记有图
>
> 安装ES
>
> > 有一些默认的值需要针对不同技术做调整
> >
> > 需要调整root以外的用户使用的线程最大数量和虚拟内存大小原因`elasticsearch`不允许root启动
>
> > 调整linux的环境
> >
> > > 添加es:es用户:用户组
> > >
> > > 对除了root用户以外的所有用户设置的线程分配最大值2048(默认1024)
> > >
> > > > `[root@10-9-104-184 limits.d]#
> > > > vim /etc/security/limits.d/90-nproc.conf`
> > > >
> > > > `*	soft	nproc	2048`
> > >
> > > 对es启动分配的虚拟内存容量设置成655360
>
> 
>
> 安装和配置ELASTICSEARCH单节点
>
> > 获取解压安装包
> >
> > > `[root@10-9-104-184 software]# cp
> > > /home/resources/elasticsearch-5.5.2.tar.gz ./`
> > >
> > > `[root@10-9-104-184 software]#
> > > tar -xf elasticsearch-5.5.2.tar.gz`
> >
> > 文件结构
> >
> > > `bin`：命令脚本的文件
> > >
> > > `config`：配置文件elasticsearch.yml
> > >
> > > `data`：索引本地库
> > >
> > > `log`：默认日志文件本地存放
> > >
> > > `plugins`：插件，ik插件
> > >
> > > `modules`：对接语言插件使用
>
> 
>
> 配置加载的核心文件	`config/elasticsearch.yml`
>
> > 详见笔记
>
> > 修改集群名称为：elasticsearch
> >
> > 修改节点名称
> >
> > 关闭bootstrap加载
> >
> > 配置network访问ip地址（云主机地址）
> >
> > 端口号http访问的接口
> >
> > 添加head的html5插件控制访问es的权限开放
>
> 
>
> ES的启动
>
> > `$ elasticsearch`
> >
> > > 在前台运行
> >
> > `$elasticsearch -d`
> >
> > > 在后台运行
>
>
> 索引文件的切分
>
> > es管理的所有索引文件,在默认情况下,被切分成5分
> >
> > 每份默认有一个副本一个索引一共应该有10个分片
>
> 
>
> 安装一个可视化的es插件head
>
> > 插件在云主机中预先已安装完成
>
> > `vim Gruntfile.js`
> >
> > 将主机名称改为云主机的地址
> >
> > 运行命令启动head插件(node.js)
> >
> > 启动成功后可以直接在客户端浏览器连接
> >
> > > `10.9.104.184:9200`
>
> 
>
> es的操作命令
>
> > 详见笔记中的`es使用命令.txt`
> >
> > > 索引操作
> > >
> > > > 新建索引
> > > >
> > > > 读写权限设置
> > > >
> > > > 查看索引
> > > >
> > > > 删除索引
> > > >
> > > > 打开关闭索引
> > >
> > > 文档管理
> > >
> > > > 索引与数据库的对比
> > > >
> > > > 新增文档
> > > >
> > > > 获取文档
> > > >
> > > > 删除文档
> > >
> > > 搜索操作
> > >
> > > > 查询所有（match_all）
> > > >
> > > > 词项查询（termquery）
> > > >
> > > > 多域查询
> > > >
> > > > > 将 `java简介` 拆分为 `java，简，介`，分别进行查询
>
> 
>
> IK分词器
>
> > es中如果按照默认使用standard不能妈祖中文分词的要求
> >
> > 所以es支持各种分词器的插件引入
>
> > ik分词器安装
> >
> > > 将ik分词器解压到es根目录中的plugins中
> > >
> > > 将zip安装包删除，若不删除会出现加载错误提示
> > >
> > > 将文件夹解压后的默认名称`elasticsearch`修改为`analysis-ik`
> > >
> > > 启动es就可以对ik分词器做测试访问
>
> es中的约束映射
>
> > es中使用的是mapping定义不同索引中分类的数据结构内容
> >
> > 有两种mapping
> >
> > > 一种是静态
> > >
> > > 一种是动态
> >
> > 静态mapping
> >
> > > 创建索引 查询索引的mapping内容
> > >
> > > 向索引中新增一个文档数据
> > >
> > > 生成后的mapping数据结构	==详见笔记（有整理）==
> >
> > 动态mapping
> >
> > > 认为根据索引中mapping的结构在生成数据之前设定需要的内容（ik分词器）
> >
> > > 生成动态mapping案例
> > >
> > > 验证ik分词器是否对index04中的content和title域生效
> > >
> > > > 略

###### ELASTICSEARCH集群

> ELASTICSEARCH的分布式高可用

> elasticsearch的集群结构（图见笔记）
>
> > `master node`
> >
> > > 整个集群的大脑（Bully算法）
> > >
> > > 一个集群只有一个，用于维护元数据信息
> >
> > `data node`
> >
> > > 负责读写数据，管理数据分片
> >
> > `ingest node`
> >
> > > 对外访问的连接节点
> > >
> > > 内部通信其他节点实现数据的对外读写
> >
> > `协调器`
> >
> > > 创建和运行集群，实现各种集群状态的同步工作
> > >
> > > 只要保证高可用即可，不需要大量协调器的存在
>
> 
>
> 搭建一个有三个节点的集群
>
> > 1.准备3个可以启动的elasticsearch的节点
> >
> > > 分词器要统一
> >
> > 修改配置文件
> >
> > > 1.所有集群节点配置协调器
> > >
> > > 2.为了防止脑裂，配置最小集群master 的有效数量
> > >
> > > > 有效数量多与集群一半，可有效防止脑裂
>
> 启动集群的自动发现
>
> > 1.指定节点是否存储索引数据，默认为true
> >
> > 2.设置默认索引分片个数
> >
> > 3.设置数据备份个数，如果只有一台机器，设置为0
>
> 脑裂
>
> > 脑裂的产生
> >
> > > 由于网络波动，导致与拿来没有宕机的节点被判断宕机
> > >
> > > 集群中出现多个master管理的情况
> >
> > > 会导致集群中的元数据不稳定，最终影响数据的使用
> >
> > es可以通过配置过半master有效数量，防止脑裂的出现
>
> 集群的选举
>
> > 一个集群中为了防止一个master宕机，导致集群不可用
> >
> > 一般配置多个master同在
> >
> > 会经过选举的逻辑（bully算法）
>
> 
>
> 附录
>
> > es的配置文件详解
> >
> > > 略





### 第十七天

> elastic搜索功能的实现 + rabbitmq

###### elastic搜索功能的实现

> quickstart
>
> > pom.xml
> >
> > > 略
> >
> > 创建一个连接对象
> >
> > > 配置连接的初始化对象
> > >
> > > > `Settings setting = 
> > > > 			Settings.builder().
> > > > 			put("cluster.name","elasticsearch").build();`
> > > >
> > > > `client = new PreBuiltTransportClient(setting);`
> > >
> > > 连接节点的信息
> > >
> > > > `InetAddress esA1 = InetAddress.getByName("10.9.104.184");`
> > > >
> > > > `InetAddress esA2 = InetAddress.getByName("10.9.100.26");`
> > > >
> > > > `InetAddress esA3 = InetAddress.getByName("10.9.39.13");`
> > >
> > > 扩展功能
> > >
> > > > `TransportAddress addresT1=
> > > > 		new InetSocketTransportAddress(esA1, 9300);`
> > > >
> > > > `TransportAddress addresT2=
> > > > 		new InetSocketTransportAddress(esA1, 9300);`
> > > >
> > > > `TransportAddress addresT3=
> > > > 		new InetSocketTransportAddress(esA1, 9300);`
> > >
> > > 客户端绑定连通节点
> > >
> > > > `client.addTransportAddress(addresT1);`
> > > >
> > > > `client.addTransportAddress(addresT2);`
> > > >
> > > > `client.addTransportAddress(addresT3);`
> >
> > 
> >
> > 索引的管理
> >
> > > 创建一个索引
> > >
> > > > 获取管理索引的对象admin
> > > >
> > > > > `IndicesAdminClient 
> > > > > 			admin = client.admin().indices();`
> > > >
> > > > 使用admin访问es
> > > >
> > > > > `CreateIndexRequestBuilder request 
> > > > > 			= admin.prepareCreate("index05");`
> > > >
> > > > 使用get方法发送请求到es
> > > >
> > > > > `CreateIndexResponse response = request.get();`
> > > >
> > > > 使用response接受返回的数据
> > > >
> > > > > `CreateIndexResponse response = request.get();`
> > > > >
> > > > > > 返回格式：`{"ack":,"shards_ack":""}`
> > >
> > > 
> > >
> > > 文档数据的创建
> > >
> > > > 封装一个product对象
> > > >
> > > > > `Product p=new Product();`
> > > > >
> > > > > `p.setProductId("product1");`
> > > > >
> > > > > `p.setProductCategory("手机");`
> > > >
> > > > 在index03中新增，document对象数据
> > > >
> > > > > 默认使用分词器为`standard`
> > > >
> > > > > `IndexRequestBuilder request = 
> > > > >        client.prepareIndex("index03", "product", p.getProductId());`
> > > >
> > > > 封装填写数据
> > > >
> > > > > product对象需要转化成json
> > > >
> > > > > `request.setSource(new ObjectMapper()
> > > > > 					.writeValueAsString(p));`
> > > >
> > > > 接受返回数据
> > > >
> > > > > `IndexResponse response = request.get();`
> > >
> > > 
> > >
> > > 获取文档对象
> > >
> > > > 获取文档数据的结构
> > > >
> > > > > `GetResponse response = 
> > > > >      client.prepareGet("index03","product", "product1").get();`
> > > >
> > > > 获取文档中的数据内容
> > > >
> > > > > `Map<String, Object> source = response.getSource();`
> > > > >
> > > > > > `ProductId="",ProductName=""..`
> > > >
> > > > 获取Map中的数据
> > > >
> > > > > `System.out.println(source.get("productName"));`
> > > >
> > > > 以json格式解析response
> > > >
> > > > > `String sourceStr = response.getSourceAsString();`
> > > > >
> > > > > > 格式：`{"name":"",""}`
> > >
> > > 
> > >
> > > 搜索 解析查询结果
> > >
> > > > 能够实现搜索功能的类
> > > >
> > > > > `termQeury matchQuery FuzzyQuery BooleanQuery`
> > > >
> > > > 书写query
> > > >
> > > > > `MatchQueryBuilder query = QueryBuilders.matchQuery("productName", "三星");`
> > > >
> > > > 添加索引
> > > >
> > > > > `SearchRequestBuilder queryRequest=
> > > > >       client.prepareSearch("index03").setQuery(query);`
> > > >
> > > > 根据指定情况定义分页
> > > >
> > > > > `queryRequest.setFrom(0);//相当于 limit start`
> > > > >
> > > > > `queryRequest.setSize(5);//相当于limit start rows`
> > > >
> > > > 使用get()发送请求
> > > >
> > > > > `SearchResponse response = queryRequest.get();`
> > > >
> > > > 解析数据	hits-->hits-->source
> > > >
> > > > > `SearchHits topHits = response.getHits();`
> > > > >
> > > > > `System.out.println("总条数"+topHits.totalHits);`
> > > > >
> > > > > `System.out.println("最大评分"+topHits.maxScore());`
> > > >
> > > > 获取数据的hits
> > > >
> > > > > `SearchHit[] hits = topHits.hits();`
> > > > >
> > > > > > `for (SearchHit hit : hits)`
>
> 
>
> easymall全局搜索功能的实现
>
> > 创建索引
> >
> > 搜索商品
>
> > 略

###### 消息队列

> 当系统并发达到上限时，系统不直接拒绝访问，而是将请求放到队列中，等待系统的空闲来处理（排队，先来先处理）

> rebbitmq
>
> > RabbitMQ是实现了高级队列协议（AMQP）的开源代理软件
> >
> > 是一种常见的企业级别的消息队列
>
> rabbitmq的结构
>
> > 客户端
> >
> > > `productor`：消息生产者
> > >
> > > `consumer`：消息消费者
>
> 连接
>
> > 客户端无论是生产者还是消费者，必须连接通rabbitmq才能操作
> >
> > > 长连接：创建一次
> > >
> > > 短链接：可以频繁创建销毁
> >
> > 交换机
> >
> > > 基于erlang语言开发的一个并发能力超高，稳定的rabbitmq软件，解决了消息并发的客户端整合问题
> >
> > 队列：queue
> >
> > > rabbitmq中存储消息数据单元的组件
>
> 
>
> rabbitmq的启动和安装
>
> > 安装
> >
> > > 1.erlang语言环境的安装
> > >
> > > > erlang的版本要与rabbit匹配
> > >
> > > 2.安装socat插件
> > >
> > > 3.安装基于rpm的rabitmq安装包
> >
> > 配置设置
> >
> > > 外网的访问权限
> >
> > web控制台
> >
> > > 可以查看rebbitmq的各种信息
> >
> > 启动
> >
> > > 进入rabbitmq的bin中，运行启动命令
> >
> > 外网控制台
> >
> > > 浏览器中连接15672端口，访问控制台
> > >
> > > > 登录名：guest
> > > >
> > > > 密码：guest
>
> 
>
> rabbitmq的五种工作模式
>
> > 简单模式
> >
> > > 生产者
> > >
> > > > 生产端定义消息的发送位置（queue名称）
> > > >
> > > > 生产者将消息发送给交换机(默认交换机为AMQP default)
> > > >
> > > > 交换机根据后端队列名称发送消息
> > >
> > > 消费者
> > >
> > > > 监听：异步非阻塞，同步循环监听一个队列
> > > >
> > > > 一旦发现新的消息，执行消费逻辑
> > > >
> > > > > 引用场景
> > > > >
> > > > > > 短信，微信，软件聊天一对一
> >
> > 代码实现
> >
> > > 准备一个客户端连接对象 channel信道
> > >
> > > > `private Channel channel;`
> > >
> > > 获取长连接,构造一个连接工程
> > >
> > > > `ConnectionFactory factory=new ConnectionFactory();`
> > >
> > > 需要将rabbitmq的连接信息提供给工程
> > >
> > > > `factory.setHost("10.9.104.184");
> > > > factory.setPort(5672);//15672web控制台 5672代码客户端端口
> > > > factory.setUsername("guest");
> > > > factory.setPassword("guest");`
> > >
> > > 从工厂获取连接
> > >
> > > > `Connection conn = factory.newConnection();`
> > >
> > > 获取短连接
> > >
> > > > `channel=conn.createChannel();`
> >
> > 
> >
> > > 生产端代码
> > >
> > > > `channel.basicPublish("", "simple02", null, msg.getBytes());`
> > > >
> > > > > (交换机名称，队列名称，消息的属性，消息体)
> >
> > > 消费端代码
> > >
> > > > 声明队列
> > > >
> > > > > `channel.queueDeclare("simple01",false, false, false, null);`
> > > > >
> > > > > > 也可以在生产端声明
> > > >
> > > > > （队列名称，是否持久化，是否专属于一个连接对象，Map类型定义了队列属性，是否自动删除）
> >
> > > 详：略



### 第十八天

> 略