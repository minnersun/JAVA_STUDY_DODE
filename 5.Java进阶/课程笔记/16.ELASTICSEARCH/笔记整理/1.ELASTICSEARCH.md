## ELASTICSEARCH

--------

### ES结构

> es是基于lucene实现的搜索服务，可以通过HTTP协议，遵循REST风格的访问，调用es实现各种功能
>
> 一个web应用，业务层封装了luncene对外提供接口访问

#### es封装lucene的结构

> 有图可见（老师笔记）

> 1.索引文件的存储
>
> > local分布式的存储	或者
> >
> > 对接hadoop lucene
>
> 2.基于lucene的功能扩展
>
> > 索引的关闭，打开
> >
> > 读写权限扩展
> >
> > 集群的功能自动发现
>
> 3.对外接口协议
>
> > http协议，REST风格

### 安装ES

> 有一些默认的值需要针对不同技术做调整
>
> 需要调整root以外的用户使用的线程最大数量和虚拟内存大小原因`elasticsearch`不允许root启动

> 调整linux的环境
>
> > 添加es:es用户:用户组
> >
> > > `[root@10-9-104-184 ~]# groupadd es`
> > >
> > > `[root@10-9-104-184 ~]# useradd es -g es -p es`
>
> > 对除了root用户以外的所有用户设置的线程分配最大值2048(默认1024)
> >
> > > `[root@10-9-104-184 limits.d]#
> > > vim /etc/security/limits.d/90-nproc.conf`
> >
> > > 修改配置文件
> > >
> > > > `*	soft	nproc	2048`
>
> > 对es启动分配的虚拟内存容量设置成655360
> >
> > > `[root@10-9-104-184 limits.d]#
> > > vim /etc/sysctl.conf`
> > >
> > > > 在最后一行添加
> > > >
> > > > > `vm.max_map_count = 655360`



### 安装和配置ELASTICSEARCH单节点

> 获取解压安装包
>
> > `[root@10-9-104-184 software]# cp
> > /home/resources/elasticsearch-5.5.2.tar.gz ./`
> >
> > `[root@10-9-104-184 software]#
> > tar -xf elasticsearch-5.5.2.tar.gz`
>
> 文件结构
>
> > `bin`：命令脚本的文件
> >
> > `config`：配置文件elasticsearch.yml
> >
> > `data`：索引本地库
> >
> > `log`：默认日志文件本地存放
> >
> > `plugins`：插件，ik插件
> >
> > `modules`：对接语言插件使用

##### 将es赋权

> > `[root@10-9-104-184 bin]# `
> >
> > `chown -R es:es /home/software/elasticsearch-5.5.2`

##### 配置加载的核心文件	config/elasticsearch.yml

> 修改集群名称为：elasticsearch
>
> > 第十七行
> >
> > > `cluster.name: elasticsearch`
>
> 修改节点名称
>
> > 第23行
> >
> > > `node.name: es02`
>
> 关闭bootstrap加载
>
> > 第43行
> >
> > > `bootstrap.memory_lock: false`
> > >
> > > `bootstrap.system_call_filter: false`
> > >
> > > > 若不关闭，加载时会有异常
>
> 配置network访问ip地址（云主机地址）
>
> > 第56行
> >
> > > `network.host: 10.9.104.184`
>
> 端口号http访问的接口
>
> > 第60行
> >
> > > `http.port:9200`
>
> 添加head的html5插件控制访问es的权限开放
>
> > 在末尾，91行添加
> >
> > > `http.cors.enabled: true`
> > >
> > > `http.cors.allow-origin: "*"`

##### ES的启动

> `su es` 
>
> > 使用es用户进入bin,调用bin下的elasticsearch脚本命令启动es
>
> `$ elasticsearch`
>
> > 在前台运行
>
> `$elasticsearch -d`
>
> > 在后台运行



### 索引文件的切分

> es管理的所有索引文件,在默认情况下,被切分成5分
>
> 每份默认有一个副本一个索引一共应该有10个分片

##### curl命令

> -X	请求方式
>
> -d ‘’	请求参数
>
> url	请求地址
>
> > 举例
> >
> > > 通过put请求在9200的es节点中创建一个索引index01
> > >
> > > > `curl -XPUT http://localhost:9200/index01`

### 安装一个可视化的es插件head

> 插件在云主机中预先已安装完成

> `/home/presoftware/elasticsearch-head-master`
>
> `[root@10-9-104-184 index]# cd /home/presoftware/elasticsearch-head-master/`
>
> `[root@10-9-104-184 elasticsearch-head-master]# vim Gruntfile.js`
>
> > 将主机名称改为云主机的地址
> >
> > > 第93行
> > >
> > > > `hostname: '10.9.10.184'`
>
> 运行命令启动head插件(node.js)
>
> > `[root@10-9-104-184 elasticsearch-head-master]# grunt server`
>
> 
>
> 启动成功后可以直接在客户端浏览器连接
>
> > `http://10.9.10.184：9100`
> >
> > > 连接此插件`ELASTICSEARCH-head`
> >
> > `http://10.9.10.184:9200`
> >
> > > 连接`ELASTICSEARCH`服务



> `curl `
>
> `-XPUT http://10.9.104.184:9200/index01`
>
> > 创建一个名为index01的索引
>
> `elasticsearch-5.5.2/data/nodes/0/indices/3uK5Vd63RlKjmo3-Q6j4tw`
>
> > `node`：存储节点信息
> >
> > `indices`：存储索引信息
> >
> > `3uK5Vd63RlKjmo3-Q6j4tw`：加密后的索引名称
> >
> > > 目录中存有文件 `0 1 2 3 4 _state`
> > >
> > >  存放具体的数据
> > >
> > > > 通过预安装软件`ELASTERSEARCH-head`可以直接读取这些数据

### es的操作命令

> 详见笔记中的`es使用命令.txt`

##### 索引操作

> 新建索引
>
> > `[root@10-9-100-26/]# `
> >
> > `curl `
> >
> > `-XPUT http://10.9.104.184:9200/index02`
>
> 读写权限设置
>
> > 可以通过post修改读写权限,可以限制读也可以限制写
> >
> > > `curl `
> > >
> > > `-XPUT -d '{"blocks.read":false}'`
> > >
> > > `http://10.9.17.153:9200/index01/_settings`
> > >
> > > > `blocks.read:true/false`
> > > >
> > > > > true限制读,false表示不限制读
> > > >
> > > > `blocks.write:true/false` 
> > > >
> > > > > true 限制写,false表示不限制写
> >
> > `[root@10-9-100-26/]# `
> >
> > `curl `
> >
> > `-XPUT -d '{"blocks.read":true}' `
> >
> > `http://10.9.104.184:9200/index01/_settings`
> >
> > > 限制了index01的任何读操作
>
> 查看索引
>
> > 略
>
> 删除索引
>
> > 略
>
> 打开关闭索引
>
> > 会释放相关线程
>
> > 略



##### 文档管理

###### 索引与数据库的对比

| ES           | 数据库   |
| ------------ | -------- |
| 索引index    | database |
| 分类type     | table    |
| 文档document | rows     |
| 域field      | column   |

> 新增文档
>
> > 请求接口	localhost:8080/索引名称/分类名称/文档自定义id值
>
> > `curl `
> >
> > `-XPUT -d '{"id":1,"title":"es简介","content":"es好用好用真好用"}' http://10.9.17.153:9200/book/article/1`
> >
> > > 自定义文档 id与数据中的 id没有关联
>
> 获取文档
>
> > 获取单个文档
> >
> > 获取多个文档
> >
> > > 略
>
> 删除文档
>
> > `curl `
> >
> > `-XDELETE http://10.9.104.184:9200/index01/article/1`

##### 搜索操作

> 查询所有（match_all）
>
> > `curl
> > -XGET http://10.9.104.184:9200/index01/_search
> > -d '{"query": {"match_all": {}}}'`
>
> 词项查询（termQuery）
>
> > `curl `
> >
> > `-XGET http://10.9.17.153:9200/index01/_search `
> >
> > `-d '{"query":{"term":{"title":"编程"}}}'`
>
> > 详细：略
>
>
> match_query
>
> > 类似于多域查询
> >
> > > 将要查询的文本进行拆分查询
> > >
> > > 还会对搜索的结果进行评分
>
> > `curl
> > -XGET http://10.9.104.184:9200/index01/_search
> > -d '{"query":{"match":{"title":"java简介"}}}'`
> >
> > > 将java简介拆分为java，简，介，分别进行查询



### MAPPING和IK分词器介绍

> es中如果按照默认使用standard不能妈祖中文分词的要求
>
> 所以es支持各种分词器的插件引入

##### ik分词器安装

> 将ik分词器解压到es根目录中的plugins中
>
> > `[root@10-9-104-184 plugins]# cp /home/resources/elasticsearch-analysis-ik-5.5.2.zip ./`
> >
> > `[root@10-9-104-184 plugins]# unzip elasticsearch-analysis-ik-5.5.2.zip `
>
> 将zip安装包删除，若不删除会出现加载错误提示
>
> > `[root@10-9-104-184plugins]# `
> >
> >  `rm -f elasticsearch-analysis-ik-5.5.2.zip `
>
> 将文件夹解压后的默认名称`elasticsearch`修改为`analysis-ik`
>
> > `[root@10-9-104-184plugins]# `
> >
> > `mv elasticsearch/ analysis-ik`
>
> 启动es就可以对ik分词器做测试访问





#### es中的约束映射

> es中使用的是mapping定义不同索引中分类的数据结构内容
>
> 有两种mapping
>
> > 一种是静态
> >
> > 一种是动态

###### 测试ik分词器在es中使用

> `10.9.104.184:9200/index01/_analyze?analyzer=ik_max_word&text=中华人民共和国`

##### 静态mapping

> 创建索引 查询索引的mapping内容
>
> > `[root@10-9-100-26 /]# `
> >
> > `curl -XPUT <http://10.9.104.184:9200/index03>`
>
> 向索引中新增一个文档数据
>
> > `[root@10-9-100-26/]# curl -XPUT `
> >
> > `-d '{"id":1,"title":"es简介","content":"es好用好用真好用"}' `
> >
> > `http://10.9.104.184:9200/index03/article/1`
>
> > 生成后的mapping数据结构
> >
> > > `index03`	：mapping所在的索引
> > >
> > > > `mappings`	：mapping所有内容
> > > >
> > > > > `article`	：当前mapping规定article内容的所有属性
> > > > >
> > > > > > `properties`	：properties域
> > > > > >
> > > > > > > `content`	
> > > > > > >
> > > > > > > > `type："text"`	：text和textField相似
> > > > > > >
> > > > > > > > `field`	
> > > > > > > >
> > > > > > > > > `keyword`
> > > > > > > > >
> > > > > > > > > > `type:"keyword"`	：keyword相当于StringFild，不计算分词
> > > > > > > > > >
> > > > > > > > > > `ignore_above:256`	：256字节以上的文本，不适用StringFild存储
> > > > > > >
> > > > > > > `id`
> > > > > > >
> > > > > > > > `type:"long"`	：整数值默认long，浮点默认float
> > > > > > >
> > > > > > > `title`
> > > > > > >
> > > > > > > > `type:"text"`
> > > > > > >
> > > > > > > > `fields`	：表示对一个域做扩展
> > > > > > > >
> > > > > > > > > `keyword`
> > > > > > > > >
> > > > > > > > > > `type："keyword"`
> > > > > > > > > >
> > > > > > > > > > `ignore_above：256`



##### 动态mapping

> 认为根据索引中mapping的结构在生成数据之前设定需要的内容（ik分词器）

> 生成动态mapping
>
> > `curl -XPUT http://10.9.104.184:9200/index04`
> >
> > `curl -XPUT -d '{"properties":{"content":{"type":"text","analyzer":"ik_max_word"},`
> >
> > `"id":{"type":"integer"},`
> >
> > `"title":{"type":"text","analyzer":"ik_max_word"}}}'`
> >
> > `http://10.9.104.184:9200/index04/_mappings/article`

> 验证ik分词器是否对index04中的content和title域生效
>
> > `curl -XPUT -d'{"id":1,"title":"java编程思想","content":"这就是个工具书"}'
> > <http://10.9.104.184:9200/index04/article/2>`
>
> > title:编程	standard肯定没有这个词项 ik分词器肯定计算出来
> >
> > > `curl -XGET http://10.9.104.184:9200/index04/_search`
> > > `-d '{"query":{"term":{"title":"编程"}}}'`

