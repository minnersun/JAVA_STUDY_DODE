## MapReduce概念

-----

### 序列化机制

> 在MapReduce中，要求被传输的数据必须能够被序列化
>
> 在MapReduce中，默认的序列化机制是**AVRO**
>
> MapReduce对AVRO进行了进一步的封装，提供了更简单的**序列化/反序列化**机制	-实现**Writable**接口，覆盖其中的**write**以及**readFields**方法





### Partitioner	- 分区

> 分区的作用是对数据进行分类
>
> 在MapReduce中，**默认**只有1个分区
>
> 每一个分区要对应一个**ReduceTask**，默认只有一个**ReduceTask**
>
> 每一个**ReduceTask**都只会产生一个结果文件
>
> 设置分区类，需要继承**Partitioner**类，覆盖其中的**getPartitioner**
>
> 分区是从**0**开始的，依次向上递增
>
> 在MapReduce中，分区类如果不指定，默认使用的是**HashPartitioner**







### 排序

> MapReduce在计算过程中，会自动对键来进行排序（自然排序）
>
> 如果需要自定义排序规则，那么对应的类需要实现**Comparable**。考虑到需要进行序列化，所以通常实现的类是**WritableComparable**
>
> 在默认情况下，如果排序规则是结果为0，则会认为这两个对象是同一个键

> 案例
>
> > 按照月份进行升序排序，如果是同一个月，那么需要按照业绩来进行降序排序
> >
> > > 文件：profit2.txt







### 数据本地化策略

> 客户端将**MR**程序交给**JobTracker**
>
> **JobTracker**在收到任务之后会找**NameNode**索要处理文件的信息，**NameNode**将信息返回**JobTracker**
>
> **JobTracker**会对文件进行切片（切片是逻辑分片，并不是整的将文件切成几份。默认情况下，切片和切块是一样大的），每一个切片对应一个**MapTask**
>
> **JobTracker**将**MapTask**分配给**TaskTracker**（实际生产环境中会将**DataNode**和**TaskTracker**部署在同一节点上）来执行，
>
> 在分配的时候，要进行满足**数据本地化策略**：谁身上有这个数据就将任务分配给谁
>
> 扩展
>
> > 如果一个文件是空文件，则这个文件整体作为一个切片
> >
> > 文件存在可切以及不可且的问题。例如绝大部分**压缩文件是不能切片**的。
> >
> > 如果一个文件不能切片，则这个文件整体作为一个切片来进行处理
> >
> > **splitSize**调小，改动**maxSize**；**splitSize**调大，改动**minSize**
> >
> > 在切片的时候有一个阈值是1.1







### Job执行流程

> 客户端先申请Job任务，同时提交jar包：`Hadoop jar xxx.jar`
>
> > 检查输入和输出路径
> >
> > 计算切片数量
> >
> > 如果有必要，设置缓存存根
> >
> > 将jar包和配置上传到HDFS上
> >
> > 提交任务，并且可以选择是否监控它的状态
>
> **JobTracker**在收到任务之后，会计算**MapTasker**的心跳。当**JobTracker**收到Tracker的心跳的时候，**JobTracker**就会给这个**TaskTracker**来分配任务
>
> **TaskTracker**领取到了任务，**TaskTracker**会连接对应的节点下载jar包，体现了逻辑移动数据的思想
>
> **TaskTracker**在下载完jar包之后，会在本节点上开启JVM子进程获取执行**MapTask**或者**ReduceTask**。注意，每执行一次**MapTask**或者**ReduceTask**，默认会开启一次JVM子进程



### Shuffle

> **Map端**的Shuffle
>
> > 每一个切片对应一个**MapTask**，在默认情况下，**MapReduce**在获取到切片之后进行读取，每读取一行，调用一次**map**方法
>
> > **map**在处理完一行数据之后，会将处理结果写入缓冲区中，当结果写入缓冲区中的时候，结果在**缓冲区中**进行分区，以及排序 -----缓冲区中的排序使用的是**快速排序**
>
> > 每一个**MapTask**都自带一个缓冲区，缓冲区是维系在内存中，默认是**100M**
>
> > 缓冲区的使用达到一定条件（在缓冲区中存在一个**阈值**，默认是**0.8**）的时候，会将缓冲区中的数据冲刷到磁盘形成的一个文件，这个冲刷过程称之为**溢写(spill)**，产生的结果文件称之为**溢写文件**，单个**溢写文件**中的数据也是分区且有序
>
> > **溢写**之后，**map**方法的后续结果继续写到缓冲区中，如果达到条件之后，会再次溢写，此时会产生一个新的溢写文件	-每一次溢写都会产生一个溢写文件，如果产生了多个溢写文件，则多个**溢写文件**之间是**无序的**	-**局部有序**
>
> > 如果多次**溢写**，产生了多个**溢写文件**，那么**MapTask**在执行结束之后，会将这些溢写文件合并成一个**结果文件(final out)**，这个合并称之为**merge**
> >
> > > 如果没有产生溢写，则缓冲区中的数据直接冲刷到final out文件中
>
> > 在**merge**过程中，数据会再次进行分区并且排序，因此final out文件是分区并且整体有序	-**将局部有序，变为整体有序**	- 使用的是**归并排序**
>
> 注意问题
>
> > Spill过程不一定会产生
> >
> > 溢写文件的大小不一定等于缓冲区容量乘以阈值
> >
> > 缓冲区本质上是一个字节数据，而且是一个环形的字节数组
> >
> > 将缓冲区设置为环形的目的是为减少寻址的时间
> >
> > 阈值的目的是为了尽量避免阻塞

> **Reduce端**的Shuffle
>
> > **ReduceTask**会启动**fetch线程**去**MapTask**端抓取数据，在抓取的时候只抓取当前**ReduceTask**对应的分区数据
>
> > **ReduceTask**将抓取来的数据放入文件中暂存，每一个**MapTask**专区的数据对应一个文件
>
> > 在抓取完成之后，**ReduceTask**会将这些小文件进行merge，合并成一个大文件。在**merge**的过程中，数据会再次进行排序。这次排序依然使用的将局部有序变成整体有序，所以依然使用的是**归并排序**
>
> > **merge**完成之后，会将相同的键对应的值放到一组，形成一个迭代器，这个过程称之为分组(group)
>
> > group之后，每一个键都会调用一次reduce方法
>
> 注意问题
>
> > 默认ReduceTask会启动5个fetch线程
> >
> > ReduceTask启动阈值是0.05，当有5%的MapTask执行结束，就会启动ReduceTask
> >
> > merge因子默认是10，表示每10个小文件合并成一个大文件

#### Shuffle的优化

> ###### 调大缓冲区，一般将缓冲区设置在250~400M之间
>
> 增大缓冲区的阈值，意味着增大阻塞的几率
>
> ###### 适当的增加Combine的过程
>
> ###### 可以考虑将final out文件进行压缩，这种方式在网络条件不好的情况下的一种取舍
>
> ###### 增加fetch线程的数量
>
> 调小ReduceTask的启动阈值(不建议)
>
> 增大merge因子（不建议）

