## Hadoop -HDFS

----

### Hadoop版本

> Hadoop1.X
>
> > 只包含Common，HDFS以及MapReduce
>
> Hadoop2.X
>
> > 包含Common，HDFS，MapReduce以及Yarn
>
> Hadoop3.0
>
> > 包含Common，HDFS，MapReduce，Yarn以及Ozone

#### 模块

> Common
>
> > 基本模块
>
> HDFS
>
> > 用于分布式**存储**
>
> Yarn
>
> > 用于完成**任务调度**和**资源管理**
>
> MapReduce
>
> > 基于Yarn进行**分布式计算**
>
> Ozone
>
> > 对象存储
>
> Submarine
>
> > Hadoop的机器学习引擎	- 2019.3





### HDFS

> Hadoop中用于进行分布式存储的组件



#### 概述

> HDFS需要有一个节点来负责**管理 **
>
> 有多个节点负责**存储**
>
> HDFS是一个典型的**主从结构**

> 负责管理的节点称之为**NameNode**，负责存储的节点称之为**DataNode**
>
> 在HDFS中，存储数据的时候，会将**数据进行切分**，切出多个数据存放到多个节点上
>
> HDFS会自动对数据块进行**备份**，每一个备份称之为是一个**副本(replication)**，在HDFS中，默认**副本数量为3**



#### Block

> 在HDFS中，数据是以Block的形式来进行存储，即每一个DataNode上，会存储多个**Block**
>
> 当文件向HDFS中放入的时候，会自动切成1个或多个Block
>
> 在Hadoop2.X中，每一个Block的大小**默认为128M**
>
> 如果一个文件**不足128M**，将这个文件作为一个Block进行存储，而这个**Block的大小与文件的大小一致**
>
> 在HDFS中，会自动对Block进行**编号**
>
> 切块的意义
>
> > 为了能存储超大文件
> >
> > 为了能够进行快速的备份



#### NameNode

> NameNode是HDFS中的主节点，负责记录**元数据（metadata）**和**管理DataNode**
>
> **元数据**主要包含
>
> > 文件大小，文件的存储路径
> >
> > Block的大小，BlockID
> >
> > Block和DataNode的映射关系
> >
> > 副本的数量
> >
> > 文件的权限

> NameNode会将**元数据**存储在**内存**以及**磁盘**上
>
> > 存储在内存是为了查询快
> >
> > 存储在磁盘是为了数据的恢复
> >
> > > 元数据在磁盘上的存储位置由**hadoop.tmp.dir**来决定



##### NameNode元数据存储

> **元数据存储**在两类文件中
>
> > ==edits==
> >
> > > 记录写操作
> >
> > ==fismage==
> >
> > > 记录元数据
> >
> > > fismage中的元数据往往要落后于内存中的元数据
>
> NameNode在收到写操作的时候，会先记录到**edits_inprogress**文件中
>
> > 如果记录成功，则更新内存，更新完成后返回一个成功信号
> >
> > > 此时**fsimage**文件并没有改动
>
> **edits_inprogress**文件在达到一定的条件后，会将其中记录操作的结果转化为元数据，更新到**fsimage**中，同时产生一个新的**edits_inprogress**，将原来的**edits_inpregress**重命名为**edits_XXX-XXX**’



###### edits文件滚动的条件

> 空间
>
> > 当**edits_inprocess**文件达到一定的大小（**默认为64M**），会自动进行一次滚动，将操作记录到**fsimage**中
>
> 时间
>
> > 当**edits_inprogress**文件距离上一次滚动的达到指定时间（**默认3600s**）,也会进行一次滚动，将操作结果记录到**fsimage**中
>
> 重启
>
> > 当**NameNode重启**的时候，会自动将**edits_inprogress**文件中的操作转化为结果记录到**fsimage**中
>
> 强制
>
> > 使用指令
> >
> > > `hadoop dfsadmin -rollEdits`

##### NameNode管理DataNode

> NameNode通过心跳机制来管理DataNode
>
> > DataNode会定时的向NameNode发送给**心跳信息**
> >
> > > NameNode实现心跳，DataNode调用
> >
> > 如果超过了指定的时间，NameNode没有收到DataNode的心跳，**NameNode**会认为这个**DataNode**已经**失效（丢失）**
> >
> > > 这时，**NameNode**会将这个**DataNode**身上存储的Block在其他节点上重新备份，保证副本数量
> >
> > 心跳的时间是==3s==，如果超过10min没有收到信息，则认为节点丢失
>
> DataNode通过RPC的方式给NameNode发送心跳

