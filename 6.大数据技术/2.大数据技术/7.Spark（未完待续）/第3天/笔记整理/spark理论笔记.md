## spark理论笔记

---

### Spark Shuffle详解

#### Shuffle简介

> 洗牌
>
> > **按照某种分组条件，将具有相同特征的实际发往正确的分区**

#### Shuffle需要考虑的细节

> Shuffle过程中会产生大量的数据，数据量的大小可能超过服务器内存的大小
>
> > 所以**会产生多次的磁盘溢写**
>
> 为了**节约带宽**，需要考虑将数据进行**压缩**
>
> > 但是需要考虑**压缩率的问题**
> >
> > > 压缩和解压需要消耗CPU
> > >
> > > 所以需要**衡量带宽和CPU的平衡**

##### 针对一个集群，性能瓶颈

> 磁盘
>
> > 考量容量的大小和磁盘转速
> >
> > 可以考虑**用SSD来代替机械硬盘**
>
> CPU
>
> > 考量**核数**
>
> 内存
>
> > 看大小，**至少64GB**
> >
> > 也有比较大的1TB
>
> 带宽
>
> > 千兆带宽，万兆带宽以上

##### 生产环境中容易出现的瓶颈

> 生产环境中的**瓶颈最容易出现在带宽上**
>
> 所以很多大数据框架都会通过各种机制节省对带宽的消耗
>
> > 解决方案
> >
> > > 1.开启**压缩**机制
> > >
> > > 2.**combine**机制
> > >
> > > 3.**数据本地化策略**
> > >
> > > > 需要考虑序列化框架的好坏，比如说**avro**

#### Spark的Shuffle管理机制

> Spark目前提供两种Shuffle Manager
>
> > **Hash Based Shuffle Manager**
> >
> > **Sort Based Shuffle Manager**

##### Task

> **一个分区对应一个Task**
>
> > Task分为两种
> >
> > > **Map TASK**
> > >
> > > **Result Task**
>
> > **Shuffle Write**过程
> >
> > > **Map Task**根据**Result Task**溢写数据，生成对应数量的溢写文件
> >
> > **Shuffle Read**过程
> >
> > > **Result Task**到**Map Task**端，获取（**fetch**)属于自己分区的数据

##### Hash Based Shuffle Manager 的特点

> 每一个**MapTask**会产生对应**Result Task**数量的**临时文件(溢写文件)**
>
> Shuffle过程中，**没有任何的排序操作**，进一步**提高执行效率**

> Hash Base Shuffle管理器**潜在的问题**
>
> > 可能会**产生很多的临时文件**
> >
> > > 总的临时文件数 = Map Task * Map Task
>
> > 同时打开大量的**临时文件会占用大量的内存**
> >
> > > 由于大量文件的存在，会带来**大量磁盘的随机I/O**，降低整体的性能



##### Sort Based Shuffle Manager	-目前Shuffle默认的管理器

> 每一个Map Task 只会产生一个Shuffle临时文件
>
> > 文件中存储了所有Reault Task分区数据
> >
> > > 临时文件的总数量 = Map Task数量
>
> 为了Result Task高效进行Shuffle Read，会建立索引
>
> > Result Task通过索引信息，可以快速定位到属于自己的分区数据，进行Fetch



#### 思考

##### 如果Shuffle过程，中间结果不落地，全部基于内存来处理会产生的问题

> 1.报**内存溢出**
>
> > 生产环境，数量较大
>
> 2.不报错，但是需要**运行相当长的时间**
>
> > 在产生Shuffle时，如果某个子分区数据丢失
> >
> > 会**找**所有的**父分区做数据恢复**
> >
> > > 最糟糕的情况，**导致整个计算链重新计算**

> 所以**目前**Spark版本，产生Shuffle时，**中间结果都要落地**



#### 面试问题

> Shuffle定义
>
> Shuffle过程需要考虑的问题
>
> Spark的Shuffle管理器





### RDD缓存机制

>**默认**情况下，RDD的数据是**用完即扔**
>
>> 用完一次后，**下一次GC垃圾回收**时，会将RDD在缓存中的**数据清理掉**
>
>> 这种默认机制不会影响程序的正常执行
>>
>> > 但是当子分区**数据丢失时，重新恢复的代价会比较大**

#### RDD的缓存机制

> 1.cache
>
> > 只有一个缓存级别 即 memory_only
> >
> > > MEMORY_ONLY
> > >
> > > > 将RDD以**反序列化**的java对象形式**存储在JVM中**
> > > >
> > > > > 如果内存不够，部分数据将不被缓存
> > > >
> > > > 使用这些数据时，**需要重新计算**
>
> 2.persist
>
> > 可以指定多个缓存级别
> >
> > > MEMORY_AND_DISK
> > >
> > > > 将RDD以**反序列化**的**java对象形式存储**
> > > >
> > > > > 如果内存空间不够，将被存储到**磁盘**中
> >
> > > MEMORY_ONLY_SER
> > >
> > > > 将RDD以**序列化**的**java对象形式存储**
> > > >
> > > > > (每一个分区为一个**byte数组**)
> > >
> > > > 如果空间不够，部分数据将不被缓存
> > >
> > > 可以节省很多空间
> > >
> > > 但是CPU读取变得更加密集
> >
> > > MEMORY_AND_DISK_SER
> > >
> > > > 类似于`MEMORY_ONLY_SER`
> > >
> > > > 内存空间不够时，存储在粗盘中
> >
> > .......



### GC回收

#### 考虑如何找出垃圾数据

##### 引用计数法

> 可以标记内存中的垃圾数据
>
> > 算法思想
> >
> > > 为对象创建引用计数器
> > >
> > > > 如果其他对象引用，计数器+1
> > > >
> > > > 引用失败，计数器-1
> > >
> > > 当 计数器=0 时，此对象就是可回收的对象
>
> > 优点
> >
> > > 原理简单，判定高效，实现同意
> >
> > 缺点
> >
> > > 不能解决对象之间的循环引用问题
> > >
> > > 容易造成内存泄漏
> > >
> > > > 比如
> > > >
> > > > > String a="hello"
> > > > >
> > > > > String b="world"
> > > > >
> > > > > a=b
> > > > >
> > > > > b=a

##### 可达性分析算法

>  思想
>
> > 判断对象和GC Root 是否有相连的引用链
> >
> > > 如果没有，则是垃圾对象
> >
> > GC Root 包含内容
> >
> > > 虚拟机栈（栈帧中的本地变量表）中引用的对象
> > >
> > > 方法区中类静态属性引用的对象
> > >
> > > 方法区中常量引用的对象



#### 将标记的垃圾数据，进行回收

##### Mark-Sweep	-标记 - 清除算法

> 将标记出的数据，直接进行回收

> 优点
>
> > 回收高效，快速
>
> 缺点
>
> > 会产生大量不连续的碎片，导致内存环境质量下降
> >
> > 当分配一个比较大的对象时，若没有足够的内存地址空间，可能会提前触发一次GC
> >
> > > 而这次GC很有可能会是一次Full GC

##### Copy	复制算法

> 将内存分为一块较大的Eden空间和两块较小的Survivor空间
>
> 每次使用Eden和其中一块Survivor
>
> > 当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上
>
> 因为新生代中的对象98%都是朝生夕死，所以将新生区按照8：1：1进行划分

> 优点
>
> > 解决了Mark-Sweep产生过多内存碎片的问题
> >
> > 内存利用率提高到90%



### GC收集器

> 垃圾收集器是内存回收的具体实现

#### Serial收集器

> 这个收集器是一个单线程的收集器
>
> > 他在进行工作时，必须暂停其他所有的工作线程，直到它收集结束

#### CMS（用的较多）

> 并发低延迟收集器
>
> > 分为四个阶段
> >
> > > 初始标记
> > >
> > > > 会产生停顿，因为是扫描对象的引用链，时间很短
> > >
> > > 并发标记
> > >
> > > > GC线程和工作线程可以并发工作
> > >
> > > 重新标记
> > >
> > > > 会产生停顿
> > >
> > > 并发清除
> > >
> > > > GC线程和工作线程可以并发工作

> CMS在并发清除垃圾时，可以配置多个线程回收垃圾
>
> 优点
>
> > 停顿时间短。延迟低
>
> 缺点
>
> > 可能会产生浮动垃圾，要等到下一次GC才能收掉
>
> CMS底层是通过Mark-Sweep算法回收垃圾
>
> > 会产生垃圾碎片
> >
> > 需要定期做碎片整理



#### ParNew

> 多线程收集器，用于收集新生区的数据
>
> > 因为时多线程收集垃圾，所以产生的停顿较短
>
> > PaeNew 可以与 CMS配合使用（CMS时停顿最短的收集器）

#### Parallel（用的较多）

> 吞吐量优先收集器
>
> > 并不关注回收的时间
> >
> > 而是关注每一次尽可能多的回收垃圾