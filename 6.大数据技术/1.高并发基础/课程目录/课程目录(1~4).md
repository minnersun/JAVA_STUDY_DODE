## 课程目录

---

### 第一天

> NIO（了解） + Concurrent(BlockingQueue+CurrentMap)

##### NIO

> NIO
>
> 同步&异步
>
> > 同一时间，一个服务，只能被一个/多个线程使用
>
> 阻塞&非阻塞
>
> > 线程是都等CPU处理完成之后才处理其他任务
>
> BIO
>
> > 同步阻塞式IO
>
> > 举例
> >
> > > File，UDP，TCP
>
> > 缺点
> >
> > > 一对一连接，会产生大量的线程
>
> NIO
>
> > 同步非阻塞IO
>
> > `capacity`
> >
> > > 容量位
> > >
> > > > 用于标记缓冲区的大小
> >
> > `limit`
> >
> > > 限制位
> > >
> > > > 用于限定position所能达到的最大下标
> > > >
> > > > 默认与容量位重合
> >
> > `position`
> >
> > > 操作位
> > >
> > > > 类似于数组中的下标，用于指向操作的位置。默认位0位
> >
> > `mark`
> >
> > > 标记位
> > >
> > > > 用于进行标记
> > > >
> > > > 通常用于避免产生大量的错误
>
> NIO三大组件
>
> > 详见笔记
>
> > Buffer
> >
> > > 缓冲区，用于进行数据的==存储==
> > >
> > > `ByteBuffer buffer = ByteBuffer.allocate(10);`
> >
> > Channel
> >
> > > 通道，用于进行数据的==传输==
> > >
> > > `SocketChannel sc = SocketChannel.open();`
> > >
> > > > 客户端通道
> > >
> > > `ServerSocketChannel ssc = ServerSocketChannel.open();`
> > >
> > > > 服务端通道
> >
> > Selector 
> >
> > > 多路复用选择器
> > >
> > > 要求被选择的==通道必须是非阻塞的==
> >
> > > 选择器可以分为三类
> > >
> > > > 可接受
> > > >
> > > > 可写
> > > >
> > > > 可读

##### Concurrent包

> Concurrent包
>
> > JDK1.5提供的并发包
>
> Concurrent包主要包含了5快内容
>
> > `BlockingQueue`	- 阻塞式队列
> >
> > `ConcurrentMap`	- 并发映射
> >
> > `ExecutorService`	- 执行器服务
> >
> > `Lock`	-锁
> >
> > 原子性操作

##### BlockingQueue

> `BlockingQueue`	- 阻塞式队列
>
> > 本身是一个队列，满足==FIFO==的特点
> >
> > 阻塞队列适合于==生产消费模型==
> >
> > 阻塞队列要求元素非空
>
> > 实现类
> >
> > > 添加，删除元素，详见整理笔记
> >
> > > `ArrayBlockingQueue`	-阻塞式顺序队列
> > >
> > > > 底层基于==数组==实现，==需要指定容量==
> > >
> > > > `ArrayBlockingQueue<String> queue = new ArrayBlockingQueue<>(5);`

##### ConcurrentMap	-并发映射

> 本质上是一个Map，使用键值对的结构来进行存储
>
> `ConcurrentMap`提供了并发且安全的方式来读写数据

> Hashtable
>
> > 对外界提供的方法都是==同步非静态==的锁对象
>
> > 同步非静态的锁对象是This ---this指当前对象
> >
> > 底层基于数组+链表的存储，默认初始容量位为16
> >
> > 默认加载因子0.75
> >
> > 每次扩容默认增加一倍

> ConcurrentHashMap
>
> > 是一个**异步式线程安全的映射**
>
> > 引入了**分段 (桶)锁 机制**来解决Hashtable 带来的效率降低的问题
> >
> > 在后续的JDK版本中，`ConcurrentHashMap`在分段锁的基础上引入了**读写锁**来提高效率
>
> > JDK1.8中
> >
> > > `ConcurrentHashMap`引入了**CAS(Compare And Swap，比较交换) **无锁算法
> >
> > > 无锁算法保证线程异步安全
> > >
> > > CAS算法需要与具体的内核结合
> > >
> > > 目前市面上的内核架构都支持CAS
> >
> > > CAS
> > >
> > > > 详见笔记
> > >
> > > > 过程只要被打断，那么所有过程从头再来









###第二天

> ConcurrentHashMap + ExecurorService + LOCK

##### ConcurrentMap

###### ConcurrentHashMap

> 红黑树
>
> > 本质是一棵自平衡的二叉树
> >
> > 二叉查找树的特点
> >
> > > 左子树小于根，右子树大于根
>
> JDK1.8中，ConcurrentHashMap为了提高增删效率，引入了红黑树机制
>
> > 在`ConcurrentHashMap`中树化的条件是桶的个数  >= 64个
>
> 红黑树的特点
>
> > 略
>
> 红黑树的修正
>
> > 略
>
> 红黑树的时间复杂度
>
> > O(logN)

###### ConcurrentNavigableMap	-并发导航映射

> 1.这个映射中提供了**截取子映射**的方法 --- headMap/ ailMap/subMap
>
> 2.`ConcurrentNavigableMap`本生是一个接口所以通常使用它的实现类`ConcurrentSkipListMap` ---并发跳跃表映射 - 底层基于跳跃来实现的

> 跳跃表
>
> > 跳跃表要求元素必须有序
> >
> > 跳跃表可以形成多层，但是最上面的跳跃表中元素个数至少要两个
> >
> > 跳跃表适合于查询多的场景
> >
> > 跳跃表本省是一个典型的以空间换时间的产物
> >
> > 在跳跃表中如果是新增节点，这个节点是否要提取到跳跃表中，遵循`抛硬币`原则
> >
> > 跳跃表的空间复杂度是O(logN)

##### ExecutorService

> 详见笔记

> ExecutorService本质上是一个线程池

> 核心线程
>
> > 核心线程使用完后不会被销毁
>
> 工作队列
>
> > 本质上是一个阻塞队列
> >
> > 所有核心线程被占用，新来的请求会放入工作队列中
>
> 临时线程
>
> > 核心线程，工作队列都满了，会将新来的请求交给临时线程处理
> >
> > 临时线程处理完请求后，一段时间内不使用会被销毁
>
> RejectedExcutionHandler
>
> > 如果临时线程被全部占用，再来的请求会交给RejectedExcutionHandler来进行拒绝

###### ExecutorService 

> `ExecutorService es = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue)`
>
> > `corePoolSize` - 核心线程数量
> >
> > `maximumPoolSize` - 最大线程数量 = 核心线程数 + 临时线程数
> >
> > `keepAliveTime` - 临时线程存活时间
> >
> > `unit` - 时间单位
> >
> > `workQueue` - 工作队列
> >
> > `handler` - 拒绝执行处理器
>
> `es.execute(new ESRunnable());`
>
> > 把任务提交给线程池来执行

###### ScheduledExecutorService  

> ScheduledExecutorService  - 定时执行器
>
> > 详见笔记
>
> > 这个类能提供定时的效果
>
> `ScheduledExecutorService ses = Executors.newScheduledThreadPool(5);`
>
> `ses.scheduleAtFixedRate(
> 				new ScheduledRunnable(), 0, 
> 				5, TimeUnit.SECONDS);`
>
> > 每隔五秒执行一次，以两次任务的时间间隔为准
>
> `ses.scheduleWithFixedDelay(
> 				new ScheduledRunnable(), 0, 
> 				5, TimeUnit.SECONDS);`
>
> > 每隔五秒执行一次，以上一次的结束时间为准

###### ForkJoinPool

> 分叉
>
> > 将一个大的任务拆分成多个小任务交给多个线程来执行
>
> 合并
>
> > 将小任务的执行结果进行汇总
>
> 分叉合并的目的
>
> > 提高cpu的利用率，提高效率

> 如果数据量较大，则适合使用分叉合并
>
> 如果数据量较小，此时循环的效率反而更高

> 分叉合并过程
>
> > 分叉合并在给每一个核分配任务的时候，尽量保证每一个核的任务数量基本相等。
> >
> > 在分叉合并中，为了防止“慢任务”导致整体的效率降低，所以采取了==work-stealing（工作窃取）==策略来解决这个问题。
> >
> > 工作窃取策略
> >
> > > 是指当前核上的任务执行完成后，这个核并不会空闲下来，而是继续扫面其他的核，随机的从一个核的任务队列的尾端 **偷** 一个任务回来执行

> 案例见整理笔记



#### LOCK（待续）

> > 非静态同步方法锁是this
> >
> > 静态同步方法锁的锁对象是当前类的字节码
>
> > 在JDK1.5中，提供了Lock接口
> >
> > 通过lock方法加锁， 通过该unlock方法解锁
>
> > 锁的公平和非公平策略
> >
> > > 在非公平策略下，线程的执行次数并不均等，甚至会出现较大的差距
> > >
> > > 在公平策略下，线程的执行次数应该是均等的
> >
> > > 从效率角度考虑，非公平的效率会相对较高
> > >
> > > synchronized使用的是非公平策略
> > >
> > > Lock默认是非公平策略

##### CountDownLatch	-闭锁

> 闭锁/线程递减锁。对线程进行计数，在计数归零之前，线程会被阻塞

> 详见笔记整理













### 第三天

> LOCK

##### LOCK

###### CyclicBarrier	-栅栏

> 对线程进行计数。同样，在计数归零之前也会使线程陷入阻塞

> 案例见整理

###### CountDownLatch与CyclicBarrier对比

> CountDownLatch
>
> > 适合于一组线程结束之后需要开启另一组线程
>
> CyclicBarrier
>
> > 适合于一组线程到达同一个点之后再继续执行

> 例子
>
> > 6个人到齐了，再上菜
> >
> > > 对这个流程而言，是六个线程结束之后，再开启上菜这个新的线程，此时适用于CountDownLatchh
>
> > 6个人到齐之后开始吃饭
> >
> > > 相当于6个线程都到达同一个点后，再分别吃饭，那么此时适用于CycliBarrier

###### Exchange	-交换机

> 用于交换两个线程之间的信息

> 案例见整理



###### Semaphore	-信号量

> 控制线程的并发数

> 案例见整理



###### 原子性操作（使用不多）

> 不会被线程调度机制打断，这种操作，一旦开始，就一致运行到结束

> 案例见整理



##### Zookeeper

###### 分布式的问题

> > 为了确定读写操作所要连接的主机，需要引入管理节点
> >
> > 如果管理节点只有一个，容易存在单点故障，所以需要引入管理集群，就需要一套选举算法
> >
> > 管理集群中还需要存在崩溃恢复机制
> >
> > 主节点之间还需要进行信息的共享

###### 分布式框架的安装

> 详见课前资料

###### Zookeeper特点

> Zookeeper本身是一个树状结构 --- Znode树

> 根节点是	/	
>
> 所有的节点路径**必须以` / `为起点**进行计算
>
> Znode树维系在内存以及磁盘中
>
> > 维系在内存中的目的是为了快速操作
> >
> > 维系在磁盘中的目的是为了保证数据不丢失
>
> 在Zookeeper中，会对每一次的写操作（创建/删除/更改）分配一个**全局递增**的编号，这个编号称之为是事务id - Zxid
>
> 任意的持久节点都可以挂在子节点，但是临时节点不能挂在子节点

###### Zookeeper常见命令

> 略

###### 节点信息

> 使用全局递增的编号
>
> 案例见笔记 xlsx文件

| 属性           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| cZxid          | 这个节点的创建事务id                                         |
| ctime          | 这个节点的创建时间                                           |
| mZxid          | 这个节点的修改数据的事务id                                   |
| mtime          | 这个节点的修改数据的时间                                     |
| pZxid          | 记录子节点个数变化的事务id                                   |
| cversion       | 子节点个数变化次数                                           |
| dataVersion    | 数据版本。记录当前节点被修改的次数                           |
| aclVersion     | 记录节点权限的变化次数                                       |
| ephemeralOwner | 标记当前节点是否是一个临时节点   只要这个节点是持久节点，那么此项为0   如果这个节点是临时节点，那么此项为sessionid |
| dataLength     | 数据的字节个数                                               |
| numChildren    | 子节点个数                                                   |



|            | 持久节点              | 临时节点             |
| ---------- | --------------------- | -------------------- |
| 顺序节点   | Persistant_Sequential | Ephemeral_Sequential |
| 非顺序节点 | Persistant            | Ephemeral            |



###### 案例（单机Zookeeper）

> 详见整理

> 实现功能demo1
>
> > 连接Zookeeper
> >
> > 创建节点
> >
> > 修改节点数据
> >
> > 获取节点数据
> >
> > 删除节点
> >
> > 后去子节点
> >
> > 判断节点是否存在
>
> 实现功能demo2
>
> > 监控节点的数据是否被改动
> >
> > 监控子节点个数是否被改变
> >
> > 监控节点的增删变化







### 第四天

> Zookeeper + ZAB

##### Zookeeper

> 概述
>
> > Zookeeper将选举分为了两个阶段
> >
> > > 数据回复阶段
> > >
> > > 选举阶段
>
> 数据恢复阶段
>
> > 服务器节点寻找当前节点中的最大事务id
>
> 选举阶段
>
> > 每个节点会举荐自己当leader,并将节点信息发送给其他节点
> >
> > 其他节点收到信息后进行两两比较，进行多轮选举
> >
> > 最后胜出的节点成为leader 

###### 选举细节

> 详细见笔记整理

> 选举信息
>
> > 当前最大事务id
> >
> > 如果最大事务id一致，则比较myid
> >
> > 逻辑时钟值
> >
> > > 控制参加选举的节点都处在同一轮的选举上
>
> 比较原则
>
> > 当前节点**最大事务id**
> >
> > 如果**最大事务id**一致，则比较myid
> >
> > > 谁大选谁
>
> 选举原则
>
> > 当一个节点，胜过一半及以上节点的时候，这个节点就会成为leader
> >
> > 后续的节点只能成为follower
>
> 脑裂的产生及避免
>
> > 脑裂的产生条件
> >
> > > 集群分裂后的子集群又进行了选举
>
> > 集群会给选举出来的leader，分配一个全局递增编号	-**epochid**
> >
> > leader会将**epochid**分发给每一个follower
>
> > 如果产生了两个leader
> >
> > 集群会启动**epochid**小的leader

###### 节点的四种状态

> looking/voting	-选举状态
>
> following	-追随者/跟随着
>
> leader	-领导者
>
> observer	-观察者
>
> > 既不参与投票也不参与选举
> >
> > observer的存活与否并不影响集群的对外服务

###### 附加

> Observer集群的配置

> 查看集群中的事务的log文件



##### ZAB协议

> ZAB（Zookeeper Atomic Broadcast）概述
>
> > 专门针对Zookeeper的用于原子广播和崩溃恢复的协议

###### 原子广播

> 2PC
>
> > 准备阶段
> >
> > > 将请求分发给每一个参与者,等待反馈
> >
> > 提交阶段
> >
> > > 协调者收到所有参与者的**yes**,则要求参与者提交这个请求
> >
> > 终止阶段
> >
> > > 协调者没有收到所有参与者的**yes**,则终止该操作
>
> 2PC的核心思想
>
> > 一票否决

> 原子广播
>
> > 基于2PC，Zookeeper进行了改进，实现了原子广播
>
> leader
>
> > leader收到请求，将请求记录到本地日志文件中
> >
> > 记录成功后，征求每一个follower的意见
>
> follower
>
> > 接收到队列后，将请求取出，存放到本地日志中
>
> > 如果记录成功,返回**yes**信号
> >
> > 如果记录失败，返回**no**信号
>
> leader
>
> > 收到一半及以上的节点返回**yes**
> >
> > > leader会命令每一个节点执行这个请求
> >
> > 没有收到一半以上的节点返回**yes**
> >
> > > leader会认为这个请求不能执行
> > >
> > > 要求所有节点删除对应的日志

###### 崩溃恢复

> 崩溃恢复解决了单点故障问题

> 在崩溃恢复过程中，新选举出来的leader会分配一个递增的**epochid**
>
> 在集群中，**事务id** 实际上是由64位二进制数字（16位十六进制）组成
>
> > 其中高32位表示**epochid**
> >
> > 低32位表示的是**事务id**

> 如果某个节点**重新启动**
>
> > 那么启动后，这个节点会寻找当前节点的**最大事务id**
> >
> > 会在发消息给leader比较**事务id**是否一致
> >
> > > 如果**事务id**一致
> > >
> > > > 说明数据一致
> > >
> > > 如果**事务id**不一致
> > >
> > > > leader会将差出的操作放入队列中发送给该节点
> > > >
> > > > 在该节点恢复数据阶段，该节点不对外服务

##### AVRO

> AVRO是Apache提供的一套用于进行序列化和RPC的机制

###### 序列化

> 序列化的目的
>
> > 为了数据的存储和传输
>
> 序列化的衡量标准
>
> > 对资源的占用
> >
> > 序列化后的数据量大小
> >
> > 是否能够跨平台及跨语言

> 序列化一般在服务器平台开发中使用
>
> 后端开发一般不会用



##### RPC（理解概念）

> 详见笔记

> RPC在调用过程中，在一个节点上能够使用另外一个节点的方法，而不用实现该方法